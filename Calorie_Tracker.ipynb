{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from openai import OpenAI\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_client = OpenAI(base_url=\"https://openrouter.ai/api/v1\"\n",
    "                       ,api_key=openai_api_key\n",
    ")\n",
    "print(\"Successfully connected to OpenRouter\")\n",
    "print(openai_api_key[:5])"
   ],
   "id": "7aa03541345b8b75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def print_markdown(text):\n",
    "    display(Markdown(text))"
   ],
   "id": "bf43cc1fc5c96a31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "\n",
    "image_filename = \"images/sample.jpg\"\n",
    "img = Image.open(image_filename)\n",
    "print(f\"Image {image_filename} loaded successfully\")\n",
    "print(f\"Format: {img.format}, Size: {img.size}\")\n",
    "print(f\"Mode: {img.mode}\")\n",
    "\n",
    "image_to_analyze = img\n"
   ],
   "id": "fc0ba2670a260bf2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import io\n",
    "import base64"
   ],
   "id": "a401e8cc4c5f7a38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def encode_image_to_base64(image_path_or_pil):\n",
    "    if isinstance(image_path_or_pil, str):  # If it's a file path\n",
    "        # Check if the file exists\n",
    "        if not os.path.exists(image_path_or_pil):\n",
    "            raise FileNotFoundError(f\"Image file not found at: {image_path_or_pil}\")\n",
    "        with open(image_path_or_pil, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "    elif isinstance(image_path_or_pil, Image.Image):\n",
    "        buffer = io.BytesIO()\n",
    "        image_format = image_path_or_pil.format or \"JPEG\"\n",
    "        image_path_or_pil.save(buffer, format=image_format)\n",
    "        return base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "    else:\n",
    "        raise ValueError(\"Input must be a file path (str) or a PIL Image object.\")\n"
   ],
   "id": "e2bacfb9b2a7c16f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def query_openai_vision(client, image, prompt, model=\"qwen/qwen2.5-vl-72b-instruct:free\", max_tokens=1000):\n",
    "\n",
    "    base64_image = encode_image_to_base64(image)\n",
    "\n",
    "    try:\n",
    "        messages_to_send = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                        },\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model = model,\n",
    "            messages = messages_to_send,\n",
    "            max_tokens = max_tokens,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error calling API: {e}\""
   ],
   "id": "d763739ded43db65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "food_recognition_prompt = \"\"\"\n",
    "# Nutritional Analysis Task\n",
    "\n",
    "## Context\n",
    "You are a nutrition expert analyzing food images to provide accurate nutritional information.\n",
    "\n",
    "## Instructions\n",
    "Analyze the food item in the image and provide estimated nutritional information based on your knowledge.\n",
    "\n",
    "## Input\n",
    "- An image of a food item\n",
    "\n",
    "## Output\n",
    "Provide the following estimated nutritional information for a typical serving size or per 100g:\n",
    "- food_name (string)\n",
    "- serving_description (string, e.g., '1 slice', '100g', '1 cup')\n",
    "- calories (float)\n",
    "- fat_grams (float)\n",
    "- protein_grams (float)\n",
    "- confidence_level (string: 'High', 'Medium', or 'Low')\n",
    "\n",
    "**IMPORTANT:** give brief description related to the health benefits of each serving in the picture provided.\n",
    "\n",
    "\"\"\""
   ],
   "id": "6f97e0e1a16fd4b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Querying OpenAI Vision API...\")\n",
    "openai_desciption = query_openai_vision(\n",
    "    openai_client,\n",
    "    image_to_analyze,\n",
    "    food_recognition_prompt,\n",
    ")\n",
    "print_markdown(openai_desciption)\n",
    "display(image_to_analyze)"
   ],
   "id": "63fc18eadebeeb4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
