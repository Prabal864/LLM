{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:37:36.671098Z",
     "start_time": "2025-08-26T07:37:36.659104Z"
    }
   },
   "cell_type": "code",
   "source": "from openai import OpenAI",
   "id": "7c87afe09c74d350",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- `import os`\n",
    "    - Imports Python’s standard library module for interacting with the operating system, including environment variables.\n",
    "\n",
    "- `from dotenv import load_dotenv`\n",
    "    - Imports the `load_dotenv` function from the `python-dotenv` package, which helps load environment variables from a file into the process environment. `.env`\n",
    "\n",
    "- `load_dotenv()`\n",
    "    - Reads key-value pairs from a file in the current directory (or parent directories) and adds them to `os.environ` so they can be accessed via `os.getenv` `.env`\n"
   ],
   "id": "769504e4a9193daa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:37:37.218204Z",
     "start_time": "2025-08-26T07:37:36.729425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_client = OpenAI(base_url=\"https://openrouter.ai/api/v1\"\n",
    ",api_key=openai_api_key)\n",
    "print(\"Success!\")\n",
    "print(openai_api_key[:5])"
   ],
   "id": "770113b6b03b1566",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "sk-or\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:37:52.004267Z",
     "start_time": "2025-08-26T07:37:37.275427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "message = input(\"Enter your message: \")\n",
    "print(f\"sending message to the model: {message}\")"
   ],
   "id": "ebce15484e812141",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending message to the model: Tell me about the LLM\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:38:05.006247Z",
     "start_time": "2025-08-26T07:37:52.184054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = openai_client.chat.completions.create(\n",
    "    model=\"qwen/qwen3-235b-a22b:free\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": message}\n",
    "    ]\n",
    ")"
   ],
   "id": "3223fc5f9d53e6e5",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:38:05.081437Z",
     "start_time": "2025-08-26T07:38:05.069528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ai_repsonse = response.choices[0].message.content\n",
    "print(f\"AI response: {ai_repsonse}\")"
   ],
   "id": "29007e11f94bee2d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI response: ### What the “LLM” (Large Language Model) is\n",
      "\n",
      "| Term | What it means |\n",
      "|------|---------------|\n",
      "| **LLM** | Large Language Model – a type of artificial‑intelligence model that learns patterns in human language from enormous data sets and can generate, interpret, or transform text. |\n",
      "\n",
      "---\n",
      "\n",
      "#### 1. Core Technology\n",
      "\n",
      "1. **Transformer Architecture**  \n",
      "   * Introduced by Vaswani et al. in 2017, the transformer uses self‑attention to capture relationships between words regardless of their distance in a sentence.\n",
      "\n",
      "2. **Training**  \n",
      "   * Models are trained on billions of tokens (words, sub‑words, or characters).  \n",
      "   * Usually done with **a “masked language modeling”** objective (predict the next word) or **autoregressive** objectives (GPT) or **sequence‑to‑sequence** (BERT).\n",
      "\n",
      "3. **Scale**  \n",
      "   * “Large” refers to both number of parameters (hundreds of millions to billions) and the volume of training data.  \n",
      "   * The more massive the model, the richer its internal representation of language nuances.\n",
      "\n",
      "---\n",
      "\n",
      "#### 2. Representative Models\n",
      "\n",
      "| Year | Model | Key Features | Typical Use‑Cases |\n",
      "|------|-------|--------------|-------------------|\n",
      "| 2018 | **BERT** (Bidirectional Encoder Representations from Transformers) | Mask‑based pre‑training, bidirectional context | Sentiment analysis, question answering, token classification |\n",
      "| 2019 | **GPT‑2** | Autoregressive, large‑scale, fully generative | Text generation, creative writing, summarization |\n",
      "| 2020 | **T5** (Text-to-Text Transfer Transformer) | Treats every NLP task as a text‑to‑text problem | Translation, summarization, data‑to‑text |\n",
      "| 2020 | **RoBERTa** | Robustly optimized BERT, larger batch and longer training | Improved accuracy on GLUE, SuperGLUE benchmarks |\n",
      "| 2020 | **Transformer‑XL** | Recurrence for longer context | Long‑form text generation, discourse modeling |\n",
      "| 2021 | **GPT‑3** (175B parameters) | 175 billion params, few‑shot learning | Chatbot, code generation (Copilot), creative content |\n",
      "| 2022 | **PaLM** (Pathways Language Model) | 540 billion tokens training, 540 billion parameters | Complex reasoning, multilingual translation |\n",
      "| 2023 | **GPT‑4 / Claude‑2 / Gemini** | Multi‑modal (text + image), higher factuality, safer outputs | Advanced conversational agents, research assistance |\n",
      "\n",
      "---\n",
      "\n",
      "#### 3. Typical Capabilities\n",
      "\n",
      "| Capability | What the model does | Why it’s useful |\n",
      "|------------|--------------------|-----------------|\n",
      "| **Text generation** | Produces high‑quality prose, code snippets, stories | Content creation, automating drafting |\n",
      "| **Summarization** | Condenses long documents into key points | Faster information consumption |\n",
      "| **Question answering** | Generates answers to factual queries | Research assistants, FAQ bots |\n",
      "| **Translation** | Converts text between languages | Global communication |\n",
      "| **Dialogue** | Continues a conversation in natural tone | Chatbots, virtual assistants |\n",
      "| **Text classification** | Detects sentiment, intent, spam | Marketing, moderation |\n",
      "| **Code generation & debugging** | Writes or refactors code | Software development |\n",
      "\n",
      "---\n",
      "\n",
      "#### 4. Strengths & Limitations\n",
      "\n",
      "| Strength | Limitation | Mitigation |\n",
      "|----------|-------------|------------|\n",
      "| **Zero or few‑shot learning** | Requires careful prompting to avoid hallucinations | Prompt engineering, retrieval‑augmented generation |\n",
      "| **Multilingual** | Performance drops for low‑resource languages | Fine‑tuning on target‑language data |\n",
      "| **Rapid iteration** | Huge compute cost | Use scaled‑down or distillation variants |\n",
      "| **Access to knowledge baked into training data** | Stale or biased knowledge | Continual learning, fine‑tuning, moderation layers |\n",
      "| **Flexibility (text → text)** | May produce nonsensical or dangerous content | Guardrails, content filters, user agreements |\n",
      "\n",
      "---\n",
      "\n",
      "#### 5. Ethical & Safety Considerations\n",
      "\n",
      "1. **Bias & Fairness** – Models reflect patterns in their training data; careful filtering is essential.  \n",
      "2. **Hallucination** – Generation of false facts; mitigated by combining LLM output with retrieval from vetted sources.  \n",
      "3. **Privacy** – Training data may contain personal information; compliance with GDPR and other regulations is required.  \n",
      "4. **Misuse** – As with any powerful AI, safeguards and usage policies are crucial (e.g., preventing disinformation or phishing).\n",
      "\n",
      "---\n",
      "\n",
      "#### 6. How to Interact with an LLM\n",
      "\n",
      "1. **Via OpenAI API** – Calls like `ChatCompletion`, `Completions`, or `Embeddings`.  \n",
      "2. **Fine‑tuning** – Use domain‑specific data to specialize an LLM (OpenAI fine‑tuning, Hugging Face’s `transformers` fine‐tune).  \n",
      "3. **Prompt Engineering** – Craft prompts (“You are a helpful tutor…”) to steer the model.  \n",
      "4. **Post‑processing** – Validate or filter outputs, possibly with a secondary classifier or human review.  \n",
      "\n",
      "---\n",
      "\n",
      "#### 7. Future Trends\n",
      "\n",
      "| Trend | What it means |\n",
      "|-------|---------------|\n",
      "| **Efficient architecture** | Models like LLaMA, Alpaca bring comparable power at lower cost. |\n",
      "| **Multimodality** | Combining text with images, audio, and video (e.g., GPT‑4 multimodal). |\n",
      "| **Responsible AI** | Models with built‑in safety layers, explainability, and bias mitigation. |\n",
      "| **Active learning & continual update** | Models that update in deployment with human‑in‑the‑loop supervision. |\n",
      "| **Domain‑specialized “expert” models** | Medical, legal, scientific LLMs fine‑tuned for high‑stakes accuracy. |\n",
      "\n",
      "---\n",
      "\n",
      "### Bottom line\n",
      "\n",
      "Large Language Models are powerful, flexible AI systems that can understand and generate human language at scale. They have revolutionized many domains—from content creation to code development—but also bring challenges in bias, hallucination, and responsible deployment. Understanding their architecture, strengths, and trade‑offs is key to using them effectively and ethically.\n"
     ]
    }
   ],
   "execution_count": 44
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
